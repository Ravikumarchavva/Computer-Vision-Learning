{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac71069c-7ac5-42f1-be98-05e3fd77960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import tensorflow_datasets as tfds\n",
    "dataset, dataset_info = tfds.load(name='malaria', shuffle_files=True, with_info=True, as_supervised=True, split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64d97146-c123-4ade-b7e1-86964342a9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, [224, 224])  # Resize images to 224x224\n",
    "    image = tf.cast(image, tf.float32)  # Convert images to float32\n",
    "    return image, label\n",
    "\n",
    "# Apply preprocessing\n",
    "train_dataset, valid_dataset, test_dataset = dataset\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess)\n",
    "valid_dataset = valid_dataset.map(preprocess)\n",
    "test_dataset = test_dataset.map(preprocess)\n",
    "\n",
    "# Normalization function\n",
    "def normalise(image, label):\n",
    "    return image / 255, label\n",
    "\n",
    "# Apply normalization\n",
    "train_dataset = train_dataset.map(normalise)\n",
    "valid_dataset = valid_dataset.map(normalise)\n",
    "test_dataset = test_dataset.map(normalise)\n",
    "\n",
    "# Apply shuffling, batching, and prefetching\n",
    "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97c548a5-d1c1-4b96-8378-2655f0cb9527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Conv2D, InputLayer, RandomRotation, RandomFlip, Resizing, CenterCrop, BatchNormalization, Flatten, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras_tuner import HyperModel\n",
    "from tensorflow.keras.activation import LeakyReLU\n",
    "class CNNHyperModel(HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "\n",
    "        # Input Layer\n",
    "        model.add(InputLayer(shape=(224, 224, 3)))\n",
    "\n",
    "        # Data Augmentation Layers\n",
    "        model.add(Resizing(224, 224))\n",
    "        model.add(RandomRotation(0.2))\n",
    "        model.add(RandomFlip('horizontal'))\n",
    "        model.add(CenterCrop(200, 200))\n",
    "\n",
    "        # Convolutional Layers with tunable number of filters and kernel size\n",
    "        for i in range(4):\n",
    "            model.add(Conv2D(\n",
    "                filters=hp.Int(f'conv_{i}_filters', min_value=8, max_value=64, step=8),\n",
    "                kernel_size=hp.Choice(f'conv_{i}_kernel_size', values=[3, 5]),\n",
    "                padding='same',\n",
    "                strides=2,\n",
    "                activation=LeakyReLU(alpha=0.1)\n",
    "            ))\n",
    "            model.add(BatchNormalization())\n",
    "        \n",
    "        # Global Pooling Layer\n",
    "        model.add(Flatten())\n",
    "\n",
    "        # Fully Connected Layers with tunable units and dropout rate\n",
    "        model.add(Dense(\n",
    "            units=hp.Int('dense_1_units', min_value=64, max_value=256, step=64),\n",
    "            activation=LeakyReLU(alpha=0.1)\n",
    "        ))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(rate=hp.Float('dropout_1', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "        model.add(Dense(\n",
    "            units=hp.Int('dense_2_units', min_value=64, max_value=512, step=64),\n",
    "            activation=LeakyReLU(alpha=0.1)\n",
    "        ))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(rate=hp.Float('dropout_2', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "        # Output Layer\n",
    "        model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "        # Compile the model with a tunable learning rate\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6eb650c-a480-4f5e-8ee7-0118df0f4aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner import RandomSearch\n",
    "\n",
    "# Define the tuner\n",
    "tuner = RandomSearch(\n",
    "    CNNHyperModel(),\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  # Number of different hyperparameter combinations to try\n",
    "    executions_per_trial=2,  # Number of models to build and average\n",
    "    directory='hyper_tuning',\n",
    "    project_name='cnn_tuning'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0ae151d-b0d1-46c0-87a5-5c8723b1490e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 11m 49s]\n",
      "val_accuracy: 0.9548258483409882\n",
      "\n",
      "Best val_accuracy So Far: 0.9570029079914093\n",
      "Total elapsed time: 03h 15m 36s\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "# TensorBoard log directory\n",
    "log_dir = './logs/' + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Start the hyperparameter search\n",
    "tuner.search(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    epochs=10,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "102c1734-9b4d-4b0a-87a3-5c7c89507bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The best hyperparameters are:\n",
      "- Conv1 Filters: 16\n",
      "- Conv2 Filters: 8\n",
      "- Dense1 Units: 256\n",
      "- Dense2 Units: 64\n",
      "- Dropout1 Rate: 0.30000000000000004\n",
      "- Dropout2 Rate: 0.4\n",
      "- Learning Rate: 0.0039852321056818825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The best hyperparameters are:\n",
    "- Conv1 Filters: {best_hps.get('conv_0_filters')}\n",
    "- Conv2 Filters: {best_hps.get('conv_1_filters')}\n",
    "- Dense1 Units: {best_hps.get('dense_1_units')}\n",
    "- Dense2 Units: {best_hps.get('dense_2_units')}\n",
    "- Dropout1 Rate: {best_hps.get('dropout_1')}\n",
    "- Dropout2 Rate: {best_hps.get('dropout_2')}\n",
    "- Learning Rate: {best_hps.get('learning_rate')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7e46418-14a4-492e-8ab9-e539d3ee1419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 15:35:04.290720: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.\n",
      "2024-09-07 15:35:04.291079: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.\n",
      "2024-09-07 15:35:04.294569: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:892] Profiler found 1 GPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 15:35:04.949182: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.\n",
      "2024-09-07 15:35:04.949663: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1036] CUPTI activity buffer flushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m101/689\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 44ms/step - accuracy: 0.5786 - loss: 0.8042"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 15:35:13.917270: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.\n",
      "2024-09-07 15:35:13.917316: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m131/689\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 47ms/step - accuracy: 0.5862 - loss: 0.7828"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 15:35:15.808486: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:68] Profiler session collecting data.\n",
      "2024-09-07 15:35:15.813263: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1036] CUPTI activity buffer flushed\n",
      "2024-09-07 15:35:16.015961: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:534]  GpuTracer has collected 34087 callback api events and 34169 activity events. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m134/689\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 51ms/step - accuracy: 0.5871 - loss: 0.7807"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 15:35:16.230499: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.\n",
      "2024-09-07 15:35:16.243531: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:147] Collecting XSpace to repository: ./logs/20240907-115125/plugins/profile/2024_09_07_15_35_16/0f9d3fda392b.xplane.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 59ms/step - accuracy: 0.7448 - loss: 0.5198 - val_accuracy: 0.9253 - val_loss: 0.2086\n",
      "Epoch 2/20\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 54ms/step - accuracy: 0.9297 - loss: 0.2086 - val_accuracy: 0.9503 - val_loss: 0.1606\n",
      "Epoch 3/20\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 46ms/step - accuracy: 0.9431 - loss: 0.1738 - val_accuracy: 0.9078 - val_loss: 0.2964\n",
      "Epoch 4/20\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 47ms/step - accuracy: 0.9470 - loss: 0.1722 - val_accuracy: 0.9507 - val_loss: 0.1944\n",
      "Epoch 5/20\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 47ms/step - accuracy: 0.9500 - loss: 0.1593 - val_accuracy: 0.9539 - val_loss: 0.1649\n",
      "Epoch 6/20\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 47ms/step - accuracy: 0.9486 - loss: 0.1597 - val_accuracy: 0.9525 - val_loss: 0.1387\n",
      "Epoch 7/20\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 46ms/step - accuracy: 0.9475 - loss: 0.1618 - val_accuracy: 0.9358 - val_loss: 0.1995\n",
      "Epoch 8/20\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 47ms/step - accuracy: 0.9503 - loss: 0.1535 - val_accuracy: 0.9521 - val_loss: 0.1492\n",
      "Epoch 9/20\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 46ms/step - accuracy: 0.9514 - loss: 0.1478 - val_accuracy: 0.9496 - val_loss: 0.1449\n",
      "Epoch 10/20\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 47ms/step - accuracy: 0.9543 - loss: 0.1406 - val_accuracy: 0.9488 - val_loss: 0.1516\n",
      "Epoch 11/20\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 47ms/step - accuracy: 0.9537 - loss: 0.1416 - val_accuracy: 0.9100 - val_loss: 0.2284\n",
      "Epoch 12/20\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 47ms/step - accuracy: 0.9528 - loss: 0.1396 - val_accuracy: 0.9525 - val_loss: 0.1378\n",
      "Epoch 13/20\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 46ms/step - accuracy: 0.9546 - loss: 0.1393 - val_accuracy: 0.9579 - val_loss: 0.1251\n",
      "Epoch 14/20\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 47ms/step - accuracy: 0.9569 - loss: 0.1349 - val_accuracy: 0.9441 - val_loss: 0.2313\n",
      "Epoch 15/20\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 46ms/step - accuracy: 0.9533 - loss: 0.1429 - val_accuracy: 0.9590 - val_loss: 0.1257\n",
      "Epoch 16/20\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 47ms/step - accuracy: 0.9565 - loss: 0.1318 - val_accuracy: 0.9550 - val_loss: 0.1223\n",
      "Epoch 17/20\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 46ms/step - accuracy: 0.9557 - loss: 0.1330 - val_accuracy: 0.9503 - val_loss: 0.1674\n",
      "Epoch 18/20\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 48ms/step - accuracy: 0.9557 - loss: 0.1377 - val_accuracy: 0.9525 - val_loss: 0.1513\n",
      "Epoch 19/20\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 47ms/step - accuracy: 0.9555 - loss: 0.1350 - val_accuracy: 0.9568 - val_loss: 0.1224\n",
      "Epoch 20/20\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 47ms/step - accuracy: 0.9567 - loss: 0.1298 - val_accuracy: 0.9550 - val_loss: 0.1401\n"
     ]
    }
   ],
   "source": [
    "# Build the best model\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "log_dir = './logs/' + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1,profile_batch='100,132')\n",
    "\n",
    "# Train the best model\n",
    "history = best_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    epochs=20,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45cda33c-0cde-4313-9ff7-ff616f1f6622",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ac486cc4-33ce-4674-a0b6-a4f7bfb1deac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 32179), started 0:33:04 ago. (Use '!kill 32179' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c3602cb41485436\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c3602cb41485436\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=./logs --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9bf51f-5c67-4049-a429-c597d7d040d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
